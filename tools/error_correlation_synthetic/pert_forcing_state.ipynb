{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import xarray as xr\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from da_utils import (Forcings, perturb_forcings_ensemble, setup_output_dirs,\n",
    "                      to_netcdf_forcing_file_compress, calculate_sm_noise_to_add_magnitude,\n",
    "                      calculate_scale_n_whole_field, to_netcdf_state_file_compress,\n",
    "                      calculate_max_soil_moist_domain, convert_max_moist_n_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ===================================================== #\n",
    "# Parameter setting\n",
    "# ===================================================== #\n",
    "lat = 34.6875\n",
    "lon = -94.9375\n",
    "\n",
    "# Root directory - all other paths will be under root_dir\n",
    "root_dir = '/civil/hydro/ymao/data_assim/'\n",
    "\n",
    "# --- Time --- #\n",
    "start_time = pd.to_datetime('1980-01-01-00')\n",
    "end_time = pd.to_datetime('1989-12-31-21')\n",
    "start_year = start_time.year\n",
    "end_year = end_time.year\n",
    "state_times = pd.date_range(start_time, end_time, freq='D')\n",
    "\n",
    "# --- Inputs --- #\n",
    "# Orig. forcing netcdf basepath ('YYYY.nc' will be appended)\n",
    "force_orig_nc = os.path.join(root_dir, 'forcing/vic/Newman/{}_{}/ens_100/force.'.format(lat, lon))\n",
    "# Orig. history netcdf file\n",
    "hist_orig_nc = os.path.join(\n",
    "    root_dir,\n",
    "    ('output/vic/ArkRed/openloop.1980_1989.Maurer_param/'\n",
    "     'history/history.openloop.{}_{}.1980-01-01-00000.nc').format(lat, lon))\n",
    "# Orig state basepath ('YYYYMMDD_SSSSS.nc' will be appended); initial state not included\n",
    "state_orig_basepath = os.path.join(\n",
    "    root_dir,\n",
    "    'output/vic/ArkRed/openloop.1980_1989.Maurer_param/states/{}_{}/state.openloop.'.format(lat, lon))\n",
    "# Initial state file\n",
    "init_state_nc = os.path.join(\n",
    "    root_dir,\n",
    "    'output/vic/ArkRed/spinup.1949_1979.Maurer_param/states/state.{}_{}.19800101_00000.nc'.format(lat, lon))\n",
    "# VIC global template file\n",
    "vic_global_template_path = os.path.join(\n",
    "    root_dir, 'control/vic/hyak.global.34.6875_-94.9375.template.Maurer_param.txt')\n",
    "\n",
    "# --- Perturbation --- #\n",
    "### prec. perturbation ###\n",
    "# Number of prec. perturbation ensemble\n",
    "N_prec = 3\n",
    "# Standard deviation of prec. perturbation multiplier (fixed)\n",
    "prec_std = 1\n",
    "# Parameter in AR(1) process for prec. perturbation (fixed)\n",
    "# prec_phi = 0\n",
    "### State perturbation ###\n",
    "# Number of state perturbation ensemble\n",
    "N_state = 3\n",
    "# Percentage of max value of each state to perturb (e.g., if\n",
    "# state_perturb_sigma_percent = 5, then Gaussian noise with standard deviation\n",
    "# = 5% of max soil moisture will be added as perturbation)\n",
    "# state_perturb_sigma_percent is a list of percentage for each soil layer\n",
    "# (e.g., if there are three soil layers, then an example of state_perturb_sigma_percent is: 20,1,0.5)\n",
    "# NOTE: keep this consistent as in the dual correction system\n",
    "state_perturb_sigma_percent = [5, 5, 0.5]\n",
    "\n",
    "# --- Outputs --- #\n",
    "output_dir = 'tools/error_correlation_synthetic/output/{}_{}'.format(lat, lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_nc_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f808f700815a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ===================================================== #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# --- Load orig. forcing --- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mds_force_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_nc_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_orig_nc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'{}.nc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_year\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_year\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# --- Set up output directory --- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m force_pert_basedir = setup_output_dirs(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_nc_file' is not defined"
     ]
    }
   ],
   "source": [
    "# ===================================================== #\n",
    "# Load forcing and perturb precipitation (same multiplier for prec every day)\n",
    "# ===================================================== #\n",
    "# --- Load orig. forcing --- #\n",
    "ds_force_orig = load_nc_file(force_orig_nc + '{}.nc', start_year, end_year)\n",
    "# --- Set up output directory --- #\n",
    "force_pert_basedir = setup_output_dirs(\n",
    "    os.path.join(root_dir, output_dir),\n",
    "    mkdirs=['perturbed_forcings'])['perturbed_forcings']\n",
    "force_pert_noise_basedir = setup_output_dirs(\n",
    "    force_pert_basedir,\n",
    "    mkdirs=['corrcoef_0'])['corrcoef_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1111)\n",
    "pert_prec_cell_ensemble(N_prec, ds_force_orig, prec_std, force_pert_noise_basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pert_prec_cell_ensemble(N, ds_force_orig, prec_std, out_forcing_basedir):\n",
    "    ''' Perturb precipitation to produce a ensemble of perturbed forcing.\n",
    "        Only for one-grid-cell case.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: <int>\n",
    "        Ensemble size\n",
    "    ds_force_orig: <xr.Dataset>\n",
    "        Original VIC-format forcing\n",
    "    prec_std: <float>\n",
    "        Standard deviation of the precipitation perturbing multiplier\n",
    "    '''\n",
    "    for ens in range(N):\n",
    "        print('Perturbing precipitation ens. {}...'.format(ens+1))\n",
    "        pert_prec_cell(ens, ds_force_orig, prec_std, out_forcing_basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pert_prec_cell(ens, ds_force_orig, prec_std, out_forcing_basedir, seed=None):\n",
    "    ''' Perturb precipitation to produce a perturbed forcing.\n",
    "        Only for one-grid-cell case.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ens: <int>\n",
    "        Index of ensemble (start from 0)\n",
    "    ds_force_orig: <xr.Dataset>\n",
    "        Original VIC-format forcing\n",
    "    prec_std: <float>\n",
    "        Standard deviation of the precipitation perturbing multiplier\n",
    "    seed: <int or None>\n",
    "        Seed for random number generator; this seed will only be used locally\n",
    "        in this function and will not affect the upper-level code.\n",
    "        None for not re-assign seed in this function, but using the global seed)\n",
    "        Default: None\n",
    "    out_forcing_basedir: <str>\n",
    "        Base directory for output perturbed forcings;\n",
    "        Subdirs \"ens_<i>\" will be created, where <i> is ensemble index, 1, ..., N\n",
    "        File names will be: forc.YYYY.nc\n",
    "    '''\n",
    "    \n",
    "    # --- Aggregate orig. prec to daily --- #\n",
    "    da_prec_orig = ds_force_orig['PREC'].squeeze()  # [time]\n",
    "    da_prec_orig_daily = da_prec_orig.groupby('time.date').sum()  # [day]\n",
    "    \n",
    "    # --- Generate multipliers for daily prec. --- #\n",
    "    # Calculate mu and sigma for the lognormal distribution\n",
    "    # (here mu and sigma are mean and std of the underlying normal dist.)\n",
    "    mu = -0.5 * np.log(prec_std^2 + 1)\n",
    "    sigma = np.sqrt(np.log(prec_std^2 + 1))\n",
    "    if seed is None:\n",
    "        multiplier_prec_daily = np.random.lognormal(\n",
    "            mean=mu, sigma=sigma,\n",
    "            size=(len(da_prec_orig_daily['date'])))\n",
    "    else:\n",
    "        rng = np.random.RandomState(seed)\n",
    "        multiplier_prec_daily = rng.lognormal(\n",
    "            mean=mu, sigma=sigma,\n",
    "            size=(len(da_prec_orig_daily['date'])))\n",
    "    # --- Distribute daily multipliers to sub-daily --- #\n",
    "    da_multiplier_prec_daily = da_prec_orig_daily.copy(deep=True)\n",
    "    da_multiplier_prec_daily[:] = multiplier_prec_daily\n",
    "    da_multiplier_prec = da_prec_orig.copy(deep=True)\n",
    "    times = [pd.to_datetime(time).date() for time in da_multiplier_prec['time'].values]\n",
    "    for date, item in da_multiplier_prec.groupby('time.date'):\n",
    "        time_ind = [time == date for time in times]\n",
    "        da_multiplier_prec[time_ind] = da_multiplier_prec_daily.loc[date]\n",
    "    # --- Perturb sub-daily prec --- #\n",
    "    da_prec_pert = da_prec_orig * da_multiplier_prec\n",
    "    # --- Save perturbed prec. to file --- #\n",
    "    # Replace perturbed prec. in the original forcing data\n",
    "    ds_force_pert = ds_force_orig.copy(deep=True)\n",
    "    ds_force_pert['PREC'][:, 0, 0] = da_prec_pert\n",
    "    # Set up ensemble subdir\n",
    "    subdir_name = 'ens_{}'.format(ens+1)\n",
    "    force_pert_ens_basedir = setup_output_dirs(\n",
    "        out_forcing_basedir,\n",
    "        mkdirs=[subdir_name])[subdir_name]\n",
    "    for year, ds in ds_force_pert.groupby('time.year'):\n",
    "        to_netcdf_forcing_file_compress(\n",
    "            ds, os.path.join(force_pert_ens_basedir, 'force.{}.nc'.format(year)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pert_state_cell_ensemble(N, states_orig, scale_n_nloop, out_state_basedir, da_max_moist_n):\n",
    "    ''' Perturb precipitation to produce a ensemble of perturbed forcing.\n",
    "        Only for one-grid-cell case.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: <int>\n",
    "        Ensemble size\n",
    "    states_orig: <list>\n",
    "        List of original VIC-format states\n",
    "    scale_n_nloop: <np.array>\n",
    "        Standard deviation of noise to add for the whole field.\n",
    "        Dimension: [nloop, n] (where nloop = lat * lon = 1)\n",
    "    out_state_basedir: <str>\n",
    "        Base directory for output perturbed states;\n",
    "        Subdirs \"ens_<i>\" will be created, where <i> is ensemble index, 1, ..., N\n",
    "        File names will be: state.YYYY_SSSSS.nc\n",
    "    da_max_moist_n: <xarray.DataArray>\n",
    "            Maximum soil moisture for the whole domain and each tile\n",
    "            [unit: mm]. Soil moistures above maximum after perturbation will\n",
    "            be reset to maximum value.\n",
    "            Dimension: [lat, lon, n]\n",
    "    '''\n",
    "    \n",
    "    for ens in range(N):\n",
    "        print('Perturbing states ens. {}...'.format(ens+1))\n",
    "        pert_state_cell(ens, states_orig, scale_n_nloop, out_state_basedir, da_max_moist_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pert_state_cell(ens, states_orig, scale_n_nloop, out_state_basedir, da_max_moist_n, seed=None):\n",
    "    ''' Perturb precipitation to produce a perturbed forcing.\n",
    "        Only for one-grid-cell case.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    ens: <int>\n",
    "        Index of ensemble (start from 0)\n",
    "    states_orig: <list>\n",
    "        List of original VIC-format states\n",
    "    scale_n_nloop: <np.array>\n",
    "        Standard deviation of noise to add for the whole field.\n",
    "        Dimension: [nloop, n] (where nloop = lat * lon = 1)\n",
    "    out_state_basedir: <str>\n",
    "        Base directory for output perturbed states;\n",
    "        Subdirs \"ens_<i>\" will be created, where <i> is ensemble index, 1, ..., N\n",
    "        File names will be: state.YYYY_SSSSS.nc\n",
    "    seed: <int or None>\n",
    "        Seed for random number generator; this seed will only be used locally\n",
    "        in this function and will not affect the upper-level code.\n",
    "        None for not re-assign seed in this function, but using the global seed)\n",
    "        Default: None\n",
    "    da_max_moist_n: <xarray.DataArray>\n",
    "            Maximum soil moisture for the whole domain and each tile\n",
    "            [unit: mm]. Soil moistures above maximum after perturbation will\n",
    "            be reset to maximum value.\n",
    "            Dimension: [lat, lon, n]\n",
    "    '''\n",
    "    \n",
    "    # Generate one N(0, 1) random noise for each time step\n",
    "    if seed is None:\n",
    "        noise_standard = np.random.normal(0, 1, [len(state_times), 1])  # [time, 1]\n",
    "    else:\n",
    "        rng = np.random.RandomState(seed)\n",
    "        noise_standard = rng.normal(0, 1, [len(state_times), 1])  # [time, 1]\n",
    "    # Scale noise for each layer (and uniform for each tile)\n",
    "    noise_scaled = np.dot(noise_standard, scale_n_nloop)  # [time, n]\n",
    "    noise_scaled = noise_scaled.reshape(\n",
    "        [len(state_times), len(states_orig[0]['nlayer']), len(states_orig[0]['veg_class']),\n",
    "         len(states_orig[0]['snow_band'])])  # [time, nlayer, nveg, nsnow]\n",
    "    noise_scaled = np.rollaxis(noise_scaled, 1, 4)  # [time, nveg, nsnow, nlayer]\n",
    "    # Set up ensemble subdir\n",
    "    subdir_name = 'ens_{}'.format(ens+1)\n",
    "    state_pert_ens_basedir = setup_output_dirs(\n",
    "        state_pert_noise_basedir,\n",
    "        mkdirs=[subdir_name])[subdir_name]\n",
    "    # Add noise to the orig. states and save to file\n",
    "    for i, time in enumerate(state_times):\n",
    "        # Replace perturbed states in the orig. state\n",
    "        ds_states_pert = states_orig[i].copy(deep=True)\n",
    "        ds_states_pert['STATE_SOIL_MOISTURE'][:, :, :, 0, 0] += noise_scaled[i, :, :, :]\n",
    "        # Adjust negative SM to zero\n",
    "        sm_new = ds_states_pert['STATE_SOIL_MOISTURE'].values\n",
    "        sm_new[sm_new<0] = 0\n",
    "        # Reset perturbed soil moistures above maximum to maximum\n",
    "        max_moist = da_max_moist_n.values\n",
    "        print(max_moist.shape)\n",
    "        print(sm_new.shape)\n",
    "        sm_new[(sm_new>max_moist)] = max_moist[(sm_new>max_moist)]\n",
    "        ds_states_pert['STATE_SOIL_MOISTURE'] = sm_new\n",
    "        # Save\n",
    "        to_netcdf_state_file_compress(\n",
    "            ds_states_pert,\n",
    "            os.path.join(state_pert_ens_basedir,\n",
    "                         'state.{}_{:05d}.nc'.format(time.strftime('%Y%m%d'), time.second)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ===================================================== #\n",
    "# Load state files and perturb SM\n",
    "# ===================================================== #\n",
    "# Load states\n",
    "states_orig = []\n",
    "# Load initial state\n",
    "states_orig.append(xr.open_dataset(init_state_nc))\n",
    "# Load all times of states\n",
    "for time in state_times[1:]:\n",
    "    state_nc = state_orig_basepath + time.strftime('%Y%m%d') + '_' + '{:05d}'.format(time.second) + '.nc'\n",
    "    states_orig.append(xr.open_dataset(state_nc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --- Set up output directory --- #\n",
    "state_pert_basedir = setup_output_dirs(\n",
    "    os.path.join(root_dir, output_dir),\n",
    "    mkdirs=['perturbed_states'])['perturbed_states']\n",
    "state_pert_noise_basedir = setup_output_dirs(\n",
    "    state_pert_basedir,\n",
    "    mkdirs=['corrcoef_0'])['corrcoef_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --- Perturb all-layer SM states --- #\n",
    "# --- (Same perturbation for all tiles/layers, with different magtinude for each layer) --- #\n",
    "# Calculate perturbation scale for each layer\n",
    "da_scale = calculate_sm_noise_to_add_magnitude(\n",
    "    vic_history_path=hist_orig_nc,\n",
    "    sigma_percent=state_perturb_sigma_percent)\n",
    "# Extract maximum moisture for each layer\n",
    "nveg = len(states_orig[0]['veg_class'])\n",
    "nsnow = len(states_orig[0]['snow_band'])\n",
    "da_max_moist = calculate_max_soil_moist_domain(vic_global_template_path)\n",
    "da_max_moist_n = convert_max_moist_n_state(da_max_moist, nveg, nsnow)\n",
    "scale_n_nloop = calculate_scale_n_whole_field(\n",
    "    da_scale, nveg, nsnow)  # [lat*lon=1, n=nlayer*nveg*nsnow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perturbing states ens. 1...\n",
      "(1, 1, 36)\n",
      "(12, 1, 3, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lusers/yixinmao/.conda/envs/vic5/lib/python3.5/site-packages/ipykernel/__main__.py:54: RuntimeWarning: invalid value encountered in less\n",
      "/usr/lusers/yixinmao/.conda/envs/vic5/lib/python3.5/site-packages/ipykernel/__main__.py:59: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-81e8769ea835>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# --- Perturb states for all ensemble members --- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpert_state_cell_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_n_nloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_pert_noise_basedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mda_max_moist_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-577d3c1ad89e>\u001b[0m in \u001b[0;36mpert_state_cell_ensemble\u001b[0;34m(N, states_orig, scale_n_nloop, out_state_basedir, da_max_moist_n)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Perturbing states ens. {}...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mens\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpert_state_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_n_nloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_state_basedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mda_max_moist_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-d40735bc1db8>\u001b[0m in \u001b[0;36mpert_state_cell\u001b[0;34m(ens, states_orig, scale_n_nloop, out_state_basedir, da_max_moist_n, seed)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_moist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0msm_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm_new\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mmax_moist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_moist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm_new\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mmax_moist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mds_states_pert\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'STATE_SOIL_MOISTURE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "# --- Perturb states for all ensemble members --- #\n",
    "pert_state_cell_ensemble(N_state, states_orig, scale_n_nloop, state_pert_noise_basedir, da_max_moist_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_nc_file(nc_file, start_year, end_year):\n",
    "    ''' Loads in nc files for all years.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nc_file: <str>\n",
    "        netCDF file to load, with {} to be substituted by YYYY\n",
    "    start_year: <int>\n",
    "        Start year\n",
    "    end_year: <int>\n",
    "        End year\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    ds_all_years: <xr.Dataset>\n",
    "        Dataset of all years\n",
    "    '''\n",
    "\n",
    "    list_ds = []\n",
    "    for year in range(start_year, end_year+1):\n",
    "        # Load data\n",
    "        fname = nc_file.format(year)\n",
    "        ds = xr.open_dataset(fname)\n",
    "        list_ds.append(ds)\n",
    "        # Concat all years\n",
    "        ds_all_years = xr.concat(list_ds, dim='time')\n",
    "\n",
    "    return ds_all_years"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
